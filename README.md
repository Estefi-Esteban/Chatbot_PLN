# ğŸ¤– Chatbot PLN Multilenguaje con AnÃ¡lisis SemÃ¡ntico y Emocional

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Status](https://img.shields.io/badge/Status-Terminado-success?style=for-the-badge)

Proyecto avanzado de **Procesamiento del Lenguaje Natural (PLN)** que implementa un **chatbot multilenguaje** capaz de comprender preguntas tÃ©cnicas, detectar intenciÃ³n, analizar sentimiento y responder utilizando **bÃºsqueda semÃ¡ntica** sobre corpus reales obtenidos automÃ¡ticamente desde Wikipedia.

---

## ğŸ“Œ DescripciÃ³n general del sistema

Este proyecto implementa un **chatbot PLN hÃ­brido**, basado en tÃ©cnicas clÃ¡sicas de procesamiento del lenguaje natural, que combina:

- BÃºsqueda semÃ¡ntica mediante TF-IDF y LSA
- AnÃ¡lisis de sentimiento multilenguaje
- DetecciÃ³n de intenciÃ³n
- GestiÃ³n de contexto conversacional
- Soporte multilenguaje (EspaÃ±ol, InglÃ©s, FrancÃ©s e Italiano)
- Scraping y procesamiento automÃ¡tico de corpus
- Persistencia de conversaciones
- Interfaz web interactiva

El objetivo del sistema es **simular un asistente conversacional inteligente**, sin depender directamente de modelos LLM, manteniendo **control total del conocimiento y del comportamiento del bot**.

---

## ğŸŒ Idiomas soportados

- ğŸ‡ªğŸ‡¸ EspaÃ±ol  
- ğŸ‡¬ğŸ‡§ InglÃ©s  
- ğŸ‡«ğŸ‡· FrancÃ©s  
- ğŸ‡®ğŸ‡¹ Italiano  

El idioma se detecta automÃ¡ticamente y se mantiene durante toda la sesiÃ³n.

---

## ğŸ§  Funcionalidades principales

### âœ… Procesamiento del Lenguaje Natural
- TokenizaciÃ³n
- NormalizaciÃ³n de texto
- EliminaciÃ³n de stopwords
- LematizaciÃ³n segÃºn idioma

### âœ… BÃºsqueda semÃ¡ntica
- VectorizaciÃ³n TF-IDF
- ReducciÃ³n de dimensionalidad mediante **LSA (Latent Semantic Analysis)**
- Similaridad coseno

### âœ… DetecciÃ³n de intenciÃ³n
- ClasificaciÃ³n basada en reglas y palabras clave
- Intenciones soportadas:
  - DefiniciÃ³n
  - Uso / Aplicaciones
  - Historia
  - Preguntas generales

### âœ… AnÃ¡lisis de sentimiento
- AnÃ¡lisis hÃ­brido combinando:
  - TextBlob
  - Diccionarios personalizados multilenguaje
- ClasificaciÃ³n:
  - Positivo
  - Negativo
  - Neutral

### âœ… Contexto conversacional
- RecuperaciÃ³n de mensajes anteriores desde base de datos
- Uso del contexto para mejorar la relevancia semÃ¡ntica

### âœ… Fallback emocional
- Respuestas empÃ¡ticas cuando no se encuentra una respuesta clara en el corpus

### âœ… Persistencia de datos
- Almacenamiento de conversaciones en **SQLite**
- Registro de:
  - Mensaje del usuario
  - Respuesta del bot
  - Idioma
  - Sentimiento
  - Polaridad

### âœ… Interfaz web
- Frontend desarrollado con **Streamlit**
- Interfaz sencilla e intuitiva
- VisualizaciÃ³n clara de respuestas y contexto

---

## ğŸ—‚ï¸ Estructura del proyecto

## ğŸ“ Estructura del Proyecto

CHATBOT_PLN/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py              # Endpoints FastAPI del chatbot
â”‚   â”‚
â”‚   â”œâ”€â”€ chatbot/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ core.py                # NÃºcleo del chatbot (LSA + contexto + emociones)
â”‚   â”‚   â”œâ”€â”€ language.py            # DetecciÃ³n de idioma (heurÃ­sticas + langdetect)
â”‚   â”‚   â”œâ”€â”€ preprocessing.py       # NormalizaciÃ³n y limpieza de texto
â”‚   â”‚   â””â”€â”€ sentiment.py           # AnÃ¡lisis de sentimiento multilenguaje
â”‚   â”‚
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ crud.py                # Operaciones CRUD para la base de datos
â”‚   â”‚   â”œâ”€â”€ database.py            # ConfiguraciÃ³n SQLite
â”‚   â”‚   â”œâ”€â”€ models.py              # Modelos ORM
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ logger.py              # Sistema de logging
â”‚   â”‚   â””â”€â”€ download_nltk.py       # Descarga automÃ¡tica de recursos NLTK
â”‚   â”‚
â”‚   â”œâ”€â”€ main.py                    # Punto de entrada FastAPI
â”‚   â””â”€â”€ schemas.py                 # Esquemas Pydantic
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ languages.json         # Intents y keywords por idioma
â”‚   â”‚
â”‚   â”œâ”€â”€ corpora/
â”‚   â”‚   â”œâ”€â”€ processed/             # Corpus limpio y tokenizado
â”‚   â”‚   â”‚   â”œâ”€â”€ corpus_en.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ corpus_es.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ corpus_fr.txt
â”‚   â”‚   â”‚   â””â”€â”€ corpus_it.txt
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ raw/                   # Corpus original extraÃ­do de Wikipedia
â”‚   â”‚       â”œâ”€â”€ corpus_en_api.txt
â”‚   â”‚       â”œâ”€â”€ corpus_es_api.txt
â”‚   â”‚       â”œâ”€â”€ corpus_fr_api.txt
â”‚   â”‚       â””â”€â”€ corpus_it_api.txt
â”‚   â”‚       
â”‚   â”œâ”€â”€ corpus_processor.py        # Procesamiento del corpus
â”‚   â””â”€â”€ scrapper/
â”‚       â””â”€â”€ wikipedia_scrapper.py  # Scraping automÃ¡tico de Wikipedia
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ streamlit_app.py           # Interfaz grÃ¡fica con Streamlit
â”‚
â”œâ”€â”€ chatbot.db                     # Base de datos SQLite
â”œâ”€â”€ requirements.txt               # Dependencias del proyecto
â”œâ”€â”€ README.md                      # DocumentaciÃ³n del proyecto
â”œâ”€â”€ .gitignore
â””â”€â”€ venv/                          # Entorno virtual


---

## ğŸ” ObtenciÃ³n y Procesamiento del Corpus

### Scraping automÃ¡tico
Se utiliza la librerÃ­a `wikipediaapi` para extraer informaciÃ³n relevante sobre **Procesamiento del Lenguaje Natural** en cada idioma.

Idiomas soportados:
- EspaÃ±ol
- InglÃ©s
- FrancÃ©s
- Italiano

### Limpieza y procesamiento
El corpus pasa por:
- EliminaciÃ³n de referencias `[1]`
- Limpieza de sÃ­mbolos
- SegmentaciÃ³n por frases con NLTK
- Filtrado de frases cortas o irrelevantes
- NormalizaciÃ³n lingÃ¼Ã­stica (stopwords, stemming, lematizaciÃ³n)

Esto garantiza un **corpus limpio, coherente y de alta calidad**.

---

## ğŸ› ï¸ CÃ³mo ampliar el conocimiento (Corpus)

El chatbot puede aprender sobre nuevos temas fÃ¡cilmente aÃ±adiendo nuevas fuentes de Wikipedia. Para ello, sigue este flujo de trabajo:

### 1. AÃ±adir nuevas fuentes
Modifica el archivo `data/scrapper/wikipedia_scrapper.py`. Busca la lista de temas/tÃ­tulos y aÃ±ade las pÃ¡ginas de Wikipedia que desees (ej. *"Deep Learning"*, *"Transformer (machine learning model)"*).

### 2. Ejecutar el Scraper
Descarga la informaciÃ³n en bruto ("raw") ejecutando:
```bash
python data/cropora/corpus_processor.py
```

### 3. Procesar y Limpiar el Corpus
Es **crucial** ejecutar el procesador despuÃ©s del scraping. Este script normaliza el texto, elimina ruidoy prepara los datos para el modelo TF-IDF:
```bash
python data/corpora/corpus_processor.py 
```
**Nota**: Si no ejecutas este paso, el bot no "verÃ¡" los nuevos datos aÃ±adidos.

---

## ğŸ§  Modelo NLP Utilizado

El chatbot utiliza un enfoque **clÃ¡sico y explicable de PLN**, sin LLMs:

### Pipeline semÃ¡ntico
- **TF-IDF** â†’ representaciÃ³n vectorial
- **LSA (TruncatedSVD)** â†’ reducciÃ³n semÃ¡ntica
- **Cosine Similarity** â†’ selecciÃ³n de respuesta

Este enfoque permite:
- Control total del conocimiento
- Respuestas reproducibles
- Bajo coste computacional
- Facilidad de explicaciÃ³n acadÃ©mica

---

## ğŸ¯ DetecciÃ³n de IntenciÃ³n

Se utiliza un sistema basado en **palabras clave por idioma**, configurable desde `languages.json`.

Intenciones soportadas:
- `definition` â†’ Â¿QuÃ© es...?
- `usage` â†’ Â¿Para quÃ© sirve...?
- `history` â†’ Historia y origen
- `general` â†’ ConversaciÃ³n abierta

La intenciÃ³n influye directamente en:
- El peso del contexto
- La consulta semÃ¡ntica
- El tipo de respuesta generada

---

## ğŸ˜Š AnÃ¡lisis de Sentimiento

Sistema hÃ­brido:
- **TextBlob** â†’ polaridad base
- **Diccionarios manuales multilenguaje** â†’ refuerzo semÃ¡ntico

Sentimientos detectados:
- Positive
- Neutral
- Negative

El sentimiento afecta al **fallback emocional** y al tono de la respuesta.

---

## ğŸ—„ï¸ Persistencia y Contexto

Todas las conversaciones se almacenan en una base de datos **SQLite**, guardando:
- Mensaje del usuario
- Respuesta del bot
- Idioma
- Sentimiento
- Polaridad

El bot utiliza los **Ãºltimos mensajes del usuario** como contexto para mejorar la coherencia conversacional.

---

## ğŸ¨ Interfaz de Usuario (Streamlit)

La aplicaciÃ³n cuenta con:
- Modo oscuro
- Mensajes diferenciados (usuario / bot)
- Indicador de idioma y sentimiento
- BotÃ³n de nueva conversaciÃ³n
- DiseÃ±o limpio y moderno

Pensada tanto para **uso acadÃ©mico** como para **demostraciones profesionales**.

---

## âš™ï¸ Requisitos del Sistema

### Software
- Python 3.9+
- SQLite
- Navegador web moderno

### Dependencias principales

fastapi
uvicorn
streamlit
scikit-learn
nltk
textblob
langdetect
wikipedia-api
sqlalchemy

---

## â–¶ï¸ EjecuciÃ³n del Proyecto

### 1. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 2. Ejecutar el backend
```bash
uvicorn app.main:app --reload
```

### 3. Ejecutar la interfaz
```bash
streamlit run streamlit_app.py
```

---

## ğŸ§ª Ejemplos de Uso

- ğŸ“Œ **Preguntas tÃ©cnicas**
  - Â¿QuÃ© es el procesamiento del lenguaje natural?
  - *What are NLP applications?*

- ğŸ’¬ **ConversaciÃ³n emocional**
  - *Hoy es un dÃ­a horrible*

- ğŸŒ **Multilenguaje**
  - *Aujourdâ€™hui est une mauvaise journÃ©e*
  - *Oggi mi sento triste*

---

## ğŸ“¦ Repositorio

El cÃ³digo fuente completo estÃ¡ disponible en GitHub y puede ampliarse fÃ¡cilmente con:

* Nuevos idiomas
* MÃ¡s fuentes de datos
* Modelos hÃ­bridos (PLN + LLM)
* IntegraciÃ³n de Transformers de Hugging Face

---

## ğŸ‘©â€ğŸ“ Autora

**EstefanÃ­a**

Estudiante de Inteligencia Artificial  
Proyecto de Procesamiento del Lenguaje Natural
